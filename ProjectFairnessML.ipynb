{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 1: ** Import a dataset and train classifiers ‚úÖ"
      ],
      "metadata": {
        "id": "Yj02Dgn0cqXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89P4MZJYupu",
        "outputId": "60e786de-6ef2-40c7-8b69-2e32185e5817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "!pip install fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = adult.data.features\n",
        "y = adult.data.targets\n",
        "\n",
        "# metadata\n",
        "print(adult.metadata)\n",
        "\n",
        "# variable information\n",
        "print(adult.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZIJQLijZQQ8",
        "outputId": "c2729593-c30d-4eca-debb-2aa54185c14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
            "              name     role         type      demographic  \\\n",
            "0              age  Feature      Integer              Age   \n",
            "1        workclass  Feature  Categorical           Income   \n",
            "2           fnlwgt  Feature      Integer             None   \n",
            "3        education  Feature  Categorical  Education Level   \n",
            "4    education-num  Feature      Integer  Education Level   \n",
            "5   marital-status  Feature  Categorical            Other   \n",
            "6       occupation  Feature  Categorical            Other   \n",
            "7     relationship  Feature  Categorical            Other   \n",
            "8             race  Feature  Categorical             Race   \n",
            "9              sex  Feature       Binary              Sex   \n",
            "10    capital-gain  Feature      Integer             None   \n",
            "11    capital-loss  Feature      Integer             None   \n",
            "12  hours-per-week  Feature      Integer             None   \n",
            "13  native-country  Feature  Categorical            Other   \n",
            "14          income   Target       Binary           Income   \n",
            "\n",
            "                                          description units missing_values  \n",
            "0                                                 N/A  None             no  \n",
            "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
            "2                                                None  None             no  \n",
            "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
            "4                                                None  None             no  \n",
            "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
            "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
            "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
            "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
            "9                                       Female, Male.  None             no  \n",
            "10                                               None  None             no  \n",
            "11                                               None  None             no  \n",
            "12                                               None  None             no  \n",
            "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
            "14                                       >50K, <=50K.  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess the dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Define features and target\n",
        "X = adult.data.features\n",
        "y = (adult.data.targets[\"income\"] == \">50K\").astype(int)\n",
        "\n",
        "# Identify sensitive features and other categorical/numerical features\n",
        "sensitive_features = [\"sex\"]  # Example sensitive attributes\n",
        "categorical_features = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"native-country\", \"race\"]\n",
        "numerical_features = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
        "\n",
        "X[X == '?'] = np.nan\n",
        "X.info()\n",
        "\n",
        "# Preprocessing:\n",
        "# 1. Handle Missing Values (Imputation or removal)\n",
        "X = X.dropna()\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Changing everything to integer models. Encode catagorical features, drop education (redundant)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_features:\n",
        "    label_encoder.fit(X[col])\n",
        "    X[col] = label_encoder.transform(X[col])\n",
        "for col in sensitive_features:\n",
        "    label_encoder.fit(X[col])\n",
        "    X[col] = label_encoder.transform(X[col])\n",
        "X = X.drop(columns=['education'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3Ur9KDCZm4F",
        "outputId": "d252d460-26d7-4afb-8246-4e13c9b1aa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4225d2e571cd>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[X == '?'] = np.nan\n",
            "<ipython-input-3-4225d2e571cd>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[X == '?'] = np.nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             48842 non-null  int64 \n",
            " 1   workclass       46043 non-null  object\n",
            " 2   fnlwgt          48842 non-null  int64 \n",
            " 3   education       48842 non-null  object\n",
            " 4   education-num   48842 non-null  int64 \n",
            " 5   marital-status  48842 non-null  object\n",
            " 6   occupation      46033 non-null  object\n",
            " 7   relationship    48842 non-null  object\n",
            " 8   race            48842 non-null  object\n",
            " 9   sex             48842 non-null  object\n",
            " 10  capital-gain    48842 non-null  int64 \n",
            " 11  capital-loss    48842 non-null  int64 \n",
            " 12  hours-per-week  48842 non-null  int64 \n",
            " 13  native-country  47985 non-null  object\n",
            "dtypes: int64(6), object(8)\n",
            "memory usage: 5.2+ MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4225d2e571cd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n",
            "<ipython-input-3-4225d2e571cd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n",
            "<ipython-input-3-4225d2e571cd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n",
            "<ipython-input-3-4225d2e571cd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n",
            "<ipython-input-3-4225d2e571cd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n",
            "<ipython-input-3-4225d2e571cd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n",
            "<ipython-input-3-4225d2e571cd>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoder.transform(X[col])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test train split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# One-hot encode categorical features\n",
        "#X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "sensitive_attr=X['sex']\n",
        "\n",
        "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(\n",
        "    X, y, sensitive_attr, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#Normalize the data\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.fit_transform(X_test)\n",
        "\n",
        "# Train Logistic Regression\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_lr))\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=30)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9hbu6PTa0N8",
        "outputId": "e220c2c0-83f8-4c8b-bd2d-37ead8dfe47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.841158693889585\n",
            "0.8473501879560699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 2:** The next goal is to compare and understand both these classifiers for fairness with respect to all three notions of fairness with sex as a protected charecterestic- https://fairlearn.org/v0.5.0/api_reference/fairlearn.metrics.html\n",
        "\n",
        "1) Demographic Parity difference\n",
        "2) Predictve rate parity difference/ equal opportunity difference: compares True Positive rates between different groups\n",
        "3) Equalized odds difference ‚úÖ"
      ],
      "metadata": {
        "id": "ypdbp5kV08Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.metrics import MetricFrame, demographic_parity_difference, selection_rate, equalized_odds_difference\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Function to compute group fairness metrics\n",
        "def compute_fairness_metrics(y_true, y_pred, sensitive_features):\n",
        "    mf = MetricFrame(\n",
        "        metrics={\n",
        "            \"Selection Rate\": selection_rate,\n",
        "            \"Precision\": precision_score,\n",
        "            \"Recall\": recall_score\n",
        "        },\n",
        "        y_true=y_true,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=sensitive_features\n",
        "    )\n",
        "    return {\n",
        "        \"Demographic Parity Difference\": demographic_parity_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
        "        \"Equalized Odds Difference\": equalized_odds_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
        "        #\"Predictive Parity Difference\": abs(mf.by_group[\"Precision\"].diff().iloc[0])  # difference in PPV\n",
        "    }\n",
        "\n",
        "# Compute fairness metrics for both models\n",
        "fairness_lr = compute_fairness_metrics(y_test, y_pred_lr, A_test)\n",
        "fairness_rf = compute_fairness_metrics(y_test, y_pred_rf,A_test)\n",
        "\n",
        "# Combine into a DataFrame\n",
        "fairness_results = pd.DataFrame([fairness_lr, fairness_rf], index=[\"Logistic Regression\", \"Random Forest\"])\n",
        "print(fairness_results)\n",
        "\n",
        "#output confusion matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZFkTwu_VONO",
        "outputId": "92d3bda9-2b04-4231-dc31-d0a7358bc024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Demographic Parity Difference  Equalized Odds Difference\n",
            "Logistic Regression                       0.060504                   0.149935\n",
            "Random Forest                             0.095556                   0.056921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual fairness metric computations using group-wise analysis\n",
        "\n",
        "def group_metrics(y_true, y_pred, sensitive_attr, group_val):\n",
        "    mask = (sensitive_attr == group_val)\n",
        "    y_true_group = y_true[mask]\n",
        "    y_pred_group = y_pred[mask]\n",
        "\n",
        "    tp = ((y_true_group == 1) & (y_pred_group == 1)).sum()\n",
        "    fp = ((y_true_group == 0) & (y_pred_group == 1)).sum()\n",
        "    tn = ((y_true_group == 0) & (y_pred_group == 0)).sum()\n",
        "    fn = ((y_true_group == 1) & (y_pred_group == 0)).sum()\n",
        "\n",
        "    selection_rate = (y_pred_group == 1).mean()\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0 #correct\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0 #correct\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0 #correct\n",
        "\n",
        "    return selection_rate, precision, recall, fpr\n",
        "\n",
        "# Wrapper to compute fairness metrics\n",
        "def compute_fairness(y_true, y_pred, sensitive_attr):\n",
        "    male_metrics = group_metrics(y_true, y_pred, sensitive_attr, 1)\n",
        "    female_metrics = group_metrics(y_true, y_pred, sensitive_attr, 0)\n",
        "\n",
        "    dp_diff = abs(male_metrics[0] - female_metrics[0])  # Demographic Parity: difference in selection rate\n",
        "    ppv_diff = abs(male_metrics[1] - female_metrics[1])  # Predictive Parity: difference in precision\n",
        "    eq_odds_diff = abs(male_metrics[2] - female_metrics[2]) + abs(male_metrics[3] - female_metrics[3])  # TPR + FPR diff\n",
        "\n",
        "    return {\n",
        "        \"Demographic Parity Difference\": dp_diff,\n",
        "        \"Predictive Parity Difference\": ppv_diff,\n",
        "        \"Equalized Odds Difference (TPR+FPR)\": eq_odds_diff\n",
        "    }\n",
        "\n",
        "# Compute for both models\n",
        "fairness_lr_manual = compute_fairness(y_test, y_pred_lr, A_test)\n",
        "fairness_rf_manual = compute_fairness(y_test, y_pred_rf, A_test)\n",
        "\n",
        "manual_fairness_df = pd.DataFrame([fairness_lr_manual, fairness_rf_manual],\n",
        "                                   index=[\"Logistic Regression\", \"Random Forest\"])\n",
        "print(manual_fairness_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1hHRUTsCPK_",
        "outputId": "f81f2540-d044-4a84-fcc9-5e4429e17255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Demographic Parity Difference  \\\n",
            "Logistic Regression                       0.060504   \n",
            "Random Forest                             0.095556   \n",
            "\n",
            "                     Predictive Parity Difference  \\\n",
            "Logistic Regression                      0.024276   \n",
            "Random Forest                            0.012949   \n",
            "\n",
            "                     Equalized Odds Difference (TPR+FPR)  \n",
            "Logistic Regression                             0.182251  \n",
            "Random Forest                                   0.112727  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 3:** Use other classifiers and make a more comprehensive study. Available classifiers: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LhQa7Lsz1hej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=30, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Support Vector Machine\": SVC(probability=True, random_state=42),\n",
        "    \"Neural Network\": MLPClassifier(max_iter=300, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "HbtObmDjyZwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference, selection_rate\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "def compute_fairness_metrics(y_true, y_pred, sensitive_features):\n",
        "    mf = MetricFrame(\n",
        "        metrics={\n",
        "            \"Selection Rate\": selection_rate,\n",
        "            \"Precision\": precision_score,\n",
        "            \"Recall\": recall_score\n",
        "        },\n",
        "        y_true=y_true,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=sensitive_features\n",
        "    )\n",
        "    #print(mf.by_group[\"Precision\"])\n",
        "    ppv_values = mf.by_group[\"Precision\"].dropna()\n",
        "    if len(ppv_values) >= 2:\n",
        "        ppv_diff = abs(ppv_values.iloc[0] - ppv_values.iloc[1])\n",
        "    else:\n",
        "        ppv_diff = np.nan\n",
        "    #print(ppv_diff)\n",
        "    return {\n",
        "        \"Demographic Parity Difference\": demographic_parity_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
        "        \"predictive rate parity difference\": ppv_diff,\n",
        "        \"Equalized Odds Difference\": equalized_odds_difference(y_true, y_pred, sensitive_features=sensitive_features)\n",
        "    }\n",
        "\n",
        "fairness_results = {}\n",
        "accuracy_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    fairness = compute_fairness_metrics(y_test, y_pred, A_test)\n",
        "\n",
        "    fairness_results[name] = fairness\n",
        "    accuracy_results[name] = acc\n",
        "\n",
        "# Fairness\n",
        "fairness_df = pd.DataFrame(fairness_results).T\n",
        "print(\"\\nFairness Metrics:\")\n",
        "print(fairness_df)\n",
        "\n",
        "# Accuracy\n",
        "accuracy_df = pd.DataFrame.from_dict(accuracy_results, orient='index', columns=[\"Accuracy\"])\n",
        "print(\"\\nAccuracy:\")\n",
        "print(accuracy_df)\n"
      ],
      "metadata": {
        "id": "gY4wIBv8yiUQ",
        "outputId": "29556eb6-d058-41ba-aa88-cb23afc394e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:23:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fairness Metrics:\n",
            "                        Demographic Parity Difference  \\\n",
            "Logistic Regression                          0.060504   \n",
            "Random Forest                                0.095556   \n",
            "Decision Tree                                0.127048   \n",
            "Support Vector Machine                       0.043185   \n",
            "Neural Network                               0.079564   \n",
            "XGBoost                                      0.068846   \n",
            "\n",
            "                        predictive rate parity difference  \\\n",
            "Logistic Regression                              0.024276   \n",
            "Random Forest                                    0.012949   \n",
            "Decision Tree                                    0.058750   \n",
            "Support Vector Machine                           0.122975   \n",
            "Neural Network                                   0.020928   \n",
            "XGBoost                                          0.021037   \n",
            "\n",
            "                        Equalized Odds Difference  \n",
            "Logistic Regression                      0.149935  \n",
            "Random Forest                            0.056921  \n",
            "Decision Tree                            0.097216  \n",
            "Support Vector Machine                   0.026659  \n",
            "Neural Network                           0.047492  \n",
            "XGBoost                                  0.067136  \n",
            "\n",
            "Accuracy:\n",
            "                        Accuracy\n",
            "Logistic Regression     0.841159\n",
            "Random Forest           0.847350\n",
            "Decision Tree           0.802314\n",
            "Support Vector Machine  0.847571\n",
            "Neural Network          0.846687\n",
            "XGBoost                 0.849635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 4:** Employ fairness mitigation measures on these classifiers and see if we can improve the metrics. Example- postprocessing: https://fairlearn.org/v0.5.0/api_reference/fairlearn.postprocessing.html\n"
      ],
      "metadata": {
        "id": "Ffd6oLhl1pzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 5:** More reasonable datsets- repeat the above exersice with datasets that make sense for each notion of fairness (where we can explain to the class that pursuing for example demographic parity is a reasonable goal)"
      ],
      "metadata": {
        "id": "QN94bLZg9wAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.preprocessing import CorrelationRemover\n",
        "from fairlearn.metrics import equalized_odds_difference, MetricFrame, selection_rate\n",
        "from sklearn.metrics import precision_score\n"
      ],
      "metadata": {
        "id": "DAQk-CLerGPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Use the filename exactly as it appears in the dataset\n",
        "file_path = \"bar_pass_prediction.csv\"\n",
        "\n",
        "# Load the dataset directly into a DataFrame\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"danofer/law-school-admissions-bar-passage\",\n",
        "    file_path\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\")\n",
        "print(df.head())\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from fairlearn.metrics import equalized_odds_difference, MetricFrame, selection_rate\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Drop missing values\n",
        "df = df.dropna(subset=['bar_passed', 'lsat', 'ugpa', 'sex', 'race'])\n",
        "\n",
        "# Only keep rows where bar_passed is a valid boolean\n",
        "df = df[df['bar_passed'].isin([True, False])]\n",
        "\n",
        "#  STEP 2: Convert bar_passed to numeric (1 = pass, 0 = fail)\n",
        "df['bar_pass'] = df['bar_passed'].astype(int)\n",
        "\n",
        "#  STEP 3: Encode categorical features\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
        "df['race'] = LabelEncoder().fit_transform(df['race'])\n",
        "\n",
        "#  STEP 4: Define features, target, and sensitive attribute\n",
        "X = df[['lsat', 'ugpa', 'sex', 'race']]\n",
        "y = df['bar_pass']\n",
        "A_race = df['race']\n",
        "A_sex = df['sex']  # Or switch to 'sex' if you want to evaluate by gender\n",
        "cr = CorrelationRemover(sensitive_feature_ids=['sex', 'race'])\n",
        "print(\"Full dataset race counts:\")\n",
        "print(df['race'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "# STEP 5: Train-test split\n",
        "X_train, X_test, y_train, y_test, A_race_train, A_race_test, A_sex_train, A_sex_test = train_test_split(\n",
        "    X, y, A_race, A_sex, test_size=0.3, random_state=42)\n",
        "\n",
        "#  STEP 6: Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "cr = CorrelationRemover(sensitive_feature_ids=[2, 3])  # indices of 'sex' and 'race' in X\n",
        "X_train_cr = cr.fit_transform(X_train_scaled)\n",
        "X_test_cr = cr.transform(X_test_scaled)\n",
        "\n",
        "equalized_odds_results = {}\n",
        "predictive_parity_results = {}\n",
        "\n",
        "\n",
        "selection_rates_race = {}\n",
        "selection_rates_sex = {}\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_cr, y_train)\n",
        "    y_pred = model.predict(X_test_cr)\n",
        "\n",
        "    eod_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=A_race_test)\n",
        "    equalized_odds_results[name] = eod_diff\n",
        "\n",
        "    # Predictive Parity (Precision) Difference by Race\n",
        "    mf_precision = MetricFrame(\n",
        "        metrics=precision_score,\n",
        "        y_true=y_test,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=A_race_test\n",
        "    )\n",
        "    predictive_parity_diff = mf_precision.by_group.max() - mf_precision.by_group.min()\n",
        "    predictive_parity_results[name] = predictive_parity_diff\n",
        "\n",
        "    # Accuracy\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracy_results[name] = acc\n",
        "\n",
        "    # Demographic Parity\n",
        "    dp_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=A_race_test)\n",
        "    fairness_results[name] = dp_diff\n",
        "\n",
        "    # Selection rate by race\n",
        "    metric_race = MetricFrame(\n",
        "        metrics=selection_rate,\n",
        "        y_true=y_test,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=A_race_test\n",
        "    )\n",
        "    selection_rates_race[name] = metric_race.by_group\n",
        "\n",
        "    # Selection rate by sex\n",
        "    metric_sex = MetricFrame(\n",
        "        metrics=selection_rate,\n",
        "        y_true=y_test,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=A_sex_test\n",
        "    )\n",
        "    selection_rates_sex[name] = metric_sex.by_group\n",
        "\n",
        "print(\"\\nüéØ Accuracy Scores:\")\n",
        "print(pd.Series(accuracy_results))\n",
        "\n",
        "# Demographic Parity Difference\n",
        "print(\"\\n‚öñÔ∏è Demographic Parity Differences:\")\n",
        "print(pd.Series(fairness_results))\n",
        "\n",
        "print(\"\\nüìä Selection Rates by Race:\")\n",
        "for model_name, rates in selection_rates_race.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(rates)\n",
        "\n",
        "print(\"\\nüìä Selection Rates by Sex:\")\n",
        "for model_name, rates in selection_rates_sex.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(rates)\n",
        "\n",
        "print(\"Full dataset race counts:\")\n",
        "print(df['race'].value_counts())\n",
        "\n",
        "print(\"\\nüìä Equalized Odds Differences by Race:\")\n",
        "print(pd.Series(equalized_odds_results))\n",
        "\n",
        "# Predictive Parity (Precision) Difference\n",
        "print(\"\\nüìä Predictive Parity Differences by Race:\")\n",
        "print(pd.Series(predictive_parity_results))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntcDRiVSgrm0",
        "outputId": "6712f31c-e50a-4590-c82d-1f647ae9017b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-6a296c8dc0a0>:9: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:\n",
            "   decile1b  decile3  ID  decile1  sex  race  cluster  lsat  ugpa  zfygpa  \\\n",
            "0      10.0     10.0   2     10.0  1.0   7.0      1.0  44.0   3.5    1.33   \n",
            "1       5.0      4.0   3      5.0  1.0   7.0      2.0  29.0   3.5   -0.11   \n",
            "2       3.0      2.0  36      3.0  2.0   7.0      3.0  36.0   3.5   -0.64   \n",
            "3       7.0      4.0  52      7.0  2.0   7.0      3.0  39.0   3.5    0.34   \n",
            "4       9.0      8.0  55      9.0  2.0   7.0      4.0  48.0   3.5    1.02   \n",
            "\n",
            "   ...  hisp pass_bar                bar bar_passed  tier   index6040  \\\n",
            "0  ...     0        1  a Passed 1st time       True   4.0  886.842082   \n",
            "1  ...     0        1  a Passed 1st time       True   2.0  649.999987   \n",
            "2  ...     0        1  a Passed 1st time       True   3.0  760.526298   \n",
            "3  ...     0        1  a Passed 1st time       True   3.0  807.894717   \n",
            "4  ...     0        1  a Passed 1st time       True   5.0  949.999974   \n",
            "\n",
            "     indxgrp   indxgrp2  dnn_bar_pass_prediction  gpa  \n",
            "0     g 700+     i 820+                 0.979804  3.5  \n",
            "1  f 640-700  f 640-700                 0.979804  3.5  \n",
            "2     g 700+  h 760-820                 0.979804  3.5  \n",
            "3     g 700+  h 760-820                 0.979804  3.5  \n",
            "4     g 700+     i 820+                 0.979804  3.5  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "Full dataset race counts:\n",
            "race\n",
            "6    18713\n",
            "2     1342\n",
            "1      897\n",
            "5      506\n",
            "3      396\n",
            "7      303\n",
            "4      125\n",
            "0      105\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:05:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Accuracy Scores:\n",
            "Logistic Regression       0.946256\n",
            "Random Forest             0.939259\n",
            "Decision Tree             0.927497\n",
            "Support Vector Machine    0.946554\n",
            "Neural Network            0.946256\n",
            "XGBoost                   0.944618\n",
            "dtype: float64\n",
            "\n",
            "‚öñÔ∏è Demographic Parity Differences:\n",
            "Logistic Regression       0.006623\n",
            "Random Forest             0.127473\n",
            "Decision Tree             0.222575\n",
            "Support Vector Machine    0.002198\n",
            "Neural Network            0.006593\n",
            "XGBoost                   0.039560\n",
            "dtype: float64\n",
            "\n",
            "üìä Selection Rates by Race:\n",
            "\n",
            "Logistic Regression:\n",
            "race\n",
            "0    1.000000\n",
            "1    1.000000\n",
            "2    0.993407\n",
            "3    1.000000\n",
            "4    1.000000\n",
            "5    0.993377\n",
            "6    0.999642\n",
            "7    1.000000\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Random Forest:\n",
            "race\n",
            "0    0.941176\n",
            "1    0.973684\n",
            "2    0.872527\n",
            "3    0.974576\n",
            "4    1.000000\n",
            "5    0.940397\n",
            "6    0.993909\n",
            "7    0.948718\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Decision Tree:\n",
            "race\n",
            "0    0.764706\n",
            "1    0.924812\n",
            "2    0.782418\n",
            "3    0.915254\n",
            "4    0.939394\n",
            "5    0.880795\n",
            "6    0.987281\n",
            "7    0.897436\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Support Vector Machine:\n",
            "race\n",
            "0    1.000000\n",
            "1    1.000000\n",
            "2    0.997802\n",
            "3    1.000000\n",
            "4    1.000000\n",
            "5    1.000000\n",
            "6    0.999821\n",
            "7    1.000000\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Neural Network:\n",
            "race\n",
            "0    1.000000\n",
            "1    1.000000\n",
            "2    0.993407\n",
            "3    1.000000\n",
            "4    1.000000\n",
            "5    1.000000\n",
            "6    0.999821\n",
            "7    1.000000\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "XGBoost:\n",
            "race\n",
            "0    0.970588\n",
            "1    0.996241\n",
            "2    0.960440\n",
            "3    1.000000\n",
            "4    0.969697\n",
            "5    0.993377\n",
            "6    0.998029\n",
            "7    0.974359\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "üìä Selection Rates by Sex:\n",
            "\n",
            "Logistic Regression:\n",
            "sex\n",
            "0    0.998292\n",
            "1    0.999736\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Random Forest:\n",
            "sex\n",
            "0    0.979508\n",
            "1    0.984956\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Decision Tree:\n",
            "sex\n",
            "0    0.960724\n",
            "1    0.968065\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Support Vector Machine:\n",
            "sex\n",
            "0    0.999317\n",
            "1    1.000000\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "Neural Network:\n",
            "sex\n",
            "0    0.998975\n",
            "1    0.999736\n",
            "Name: selection_rate, dtype: float64\n",
            "\n",
            "XGBoost:\n",
            "sex\n",
            "0    0.990437\n",
            "1    0.998153\n",
            "Name: selection_rate, dtype: float64\n",
            "Full dataset race counts:\n",
            "race\n",
            "6    18713\n",
            "2     1342\n",
            "1      897\n",
            "5      506\n",
            "3      396\n",
            "7      303\n",
            "4      125\n",
            "0      105\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìä Equalized Odds Differences by Race:\n",
            "Logistic Regression       0.020202\n",
            "Random Forest             0.242424\n",
            "Decision Tree             0.363636\n",
            "Support Vector Machine    0.010101\n",
            "Neural Network            0.020202\n",
            "XGBoost                   0.142857\n",
            "dtype: float64\n",
            "\n",
            "üìä Predictive Parity Differences by Race:\n",
            "Logistic Regression       0.180193\n",
            "Random Forest             0.155031\n",
            "Decision Tree             0.158738\n",
            "Support Vector Machine    0.181457\n",
            "Neural Network            0.180020\n",
            "XGBoost                   0.176421\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 6:** Make a presentation of our findings above (this is part 2 of the ppt)"
      ],
      "metadata": {
        "id": "Va1fryVZ-HbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal 7:** Make a presentation exlaining each notion of group fairness in a consise way (this is part 1 of our ppt)"
      ],
      "metadata": {
        "id": "Ls67mYGb-Sr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mf.by_group[\"Precision\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "F_p6C9IvEn_z",
        "outputId": "c54c0d72-2712-4f3f-e3b6-ca5ecc1ec2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a6eecef90491>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import MetricFrame, selection_rate, equalized_odds_difference\n",
        "\n",
        "# Define base classifier\n",
        "base_estimator = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Create the fairness-aware optimizer\n",
        "mitigator = ExponentiatedGradient(\n",
        "    estimator=base_estimator,\n",
        "    constraints=EqualizedOdds(),\n",
        "    sample_weight_name=\"sample_weight\"\n",
        ")\n",
        "\n",
        "# Fit with sensitive features\n",
        "mitigator.fit(X_train, y_train, sensitive_features=A_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_mitigated = mitigator.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy and fairness\n",
        "acc_mitigated = accuracy_score(y_test, y_pred_mitigated)\n",
        "eo_diff = equalized_odds_difference(y_test, y_pred_mitigated, sensitive_features=A_test)\n",
        "\n",
        "print(\"Accuracy (In-Processing):\", acc_mitigated)\n",
        "print(\"Equalized Odds Difference:\", eo_diff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wJiPUm9grJZ",
        "outputId": "46facbf9-ab16-4986-bd31-60b0c953cc41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (In-Processing): 0.924668750930475\n",
            "Equalized Odds Difference: 0.07692307692307687\n"
          ]
        }
      ]
    }
  ]
}